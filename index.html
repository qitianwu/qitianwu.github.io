<meta name="google-site-verification" content="Y50gVg4R1617ZJjuqs37mnvW9fMjlWxJ0J13I1sULSI" />
<meta name="description" content="Qitian Wu&#39;s home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Qitian Wu's Homepage @ Shanghai Jiao Tong University</title>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?f38d019abe6aa72687acdcf683ca0515";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>

<body>
<div id="layout-content" style="margin-top:25px">

<table>
    <tbody>
        <tr>
            <td width="670">
                <div id="toptitle">
                    <h1>Qitian Wu &nbsp; <!--<img src="images/name.png" height="45px" style="margin-bottom:-5px" alt=''>--></h1>
                </div>
                <p>
                    Shanghai Jiao Tong University <br>
                    Shanghai, China, 200240.<br>
                    Email: echo740@sjtu.edu.cn<br>
                    <!--
                    <a href="assets/cv.pdf">CV</a> |
                    -->
                    <a href="https://github.com/qitianwu">Github</a> | <a href="https://scholar.google.com/citations?user=m01-2qUAAAAJ&hl=zh-CN">Google Scholar</a>
                </p>
            </td>
        </tr>
    </tbody>
</table>
    

<table>
        <tbody>
            <tr>
                <th>
                    <img src="images/self3.jpeg" border="0" width="250">
                </th>
                <td style="width: 5%"></td>
                <td>
                    <p>I am now a PhD student at Department of Computer Science and Engineering from Shanghai Jiao Tong University (SJTU), advised by
                        Prof. Junchi Yan. I achieved the Bachelor (Microelectronics, Mathematics) and Master (Computer Science) degrees from SJTU.
                    </p>
                    <p>My research interests lie in structured learning and inference, out-of-distribution learning and deep generative models, with 
                        their applications on recommender systems, advertisement and healthcare service.</p>
                    <p>My current research focus on learning over semi-structured data including graphs, sequences, sets, user
                        behaviors, etc. I endeavor on developing the
                        next generation of representation learning approaches for dynamic, open and uncertain environments.</p>

                </td>
            </tr>
        </tbody>
    </table>


<h2>Recent News <small></small></h2>
<ul>
    <li>
        Papers accepted to NeurIPS'22.  <br />
    </li>


<h2>Selected Publications (see a complete list in <a href="https://scholar.google.com/citations?user=m01-2qUAAAAJ&hl=zh-CN">Google Scholar</a>) <small></small></h2>
<ul>
    <li>
        <a href="https://arxiv.org/abs/2202.02466">
            Handling Distribution Shifts on Graphs: An Invariance Perspective</a>  <br />
        <b>Qitian Wu</b>, Hengrui Zhang, Junchi Yan and David Wipf<br />
        <i>International Conference on Learning Representations</i> <b>(ICLR 2022)</b><br />
        <ul><li>Keywords: Graph Neural Networks, Out-of-Distribution Generalization, Domain-Invariant Learning</li></ul>
        <ul><li>Summary: Like neural networks that have been shown sensitive to distribution shifts on grid-structured data (images or texts),
            graph neural networks would presumably suffer similar issues on graph-structured data. As one of the piorneering works in this direction,
            we formulate out-of-distribution generalization problem on graphs and propose a new learning approach based on domain-invariant models,
            backed up with theoretical guarantees. The experiments cover synthetic spurious features, cross-graph transfer and dynamic graph evolution.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/EERM-slides.pdf"> Slides</a> |
            <a href="assets/EERM-poster.png"> Poster</a> |
            <a href="https://github.com/qitianwu/GraphOOD-EERM"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="https://arxiv.org/abs/2110.04514">
            Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach</a>  <br />
        <b>Qitian Wu</b>, Chenxiao Yang and Junchi Yan<br />
        <i>Advances in Neural Information Processing Systems</i> <b>(NeurIPS 2021)</b><br />
        <ul><li>Keywords: Attribute Feature Representation, Graph Neural Networks, Extrapolation, Domain Shift</li></ul>
        <ul><li>Summary: We propose a new research problem (domain shift from training data to testing data with augmented input feature space) and design a graph
            learning approach that bridges seen and unseen features with instance nodes to achieve extrapolation to new feature space. 
            The `open-world' term emphasizes arbitrary new features from in-the-wild environments.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/FATE-slides.pdf"> Slides</a> |
            <a href="assets/FATE-poster.png"> Poster</a> |
            <a href="https://github.com/qitianwu/FATE"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="https://arxiv.org/abs/1909.13035">
            Bridging Explicit and Implicit Deep Generative Models via Neural Stein Estimators</a>  <br />
        <b>Qitian Wu</b>, Han Gao and Hongyuan Zha<br />
        <i>Advances in Neural Information Processing Systems</i> <b>(NeurIPS 2021)</b><br />
        <ul><li>Keywords: Deep Generative Models, Energy-based Model, Generative Adversarial Networks, Stein's Method</li></ul>
        <ul><li>Summary: Explicit generative models (e.g. energy-based model) and implicit generative models (e.g. GANs) have their respective pros and cons. We leverage
            the Stein discrepancy to construct a novel bridging term to connect two models in a unified framework. We theoretically show that such an approach induces effective
            dual regularization effects and could empirically facilitate the learning of the both.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/Stein-slides.pdf"> Slides</a> |
            <a href="assets/Stein-poster.png"> Poster</a> |
            <a href="https://github.com/qitianwu/SteinBridging"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="https://arxiv.org/abs/2106.12484">
            From Canonical Correlation Analysis to Self-supervised Graph Neural Networks</a><br />
        Hengrui Zhang, <b>Qitian Wu</b>, Junchi Yan, David Wipf and Philip S. Yu<br />
        <i>Advances in Neural Information Processing Systems</i> <b>(NeurIPS 2021)</b><br />
        <ul><li>Keywords: Graph Neural Networks, Self-supervised Representation Learning, Contrastive Learning</li></ul>
        <ul><li>Summary: We introduce a simple yet effective contrastive objective for self-supervised node representation learning over graphs. 
            Compared with other works, our approach requires none of the parameterized mutual information estimator, additional projector, asymmetric structures, and most importantly, negative samples which can be costly.
        </li></ul>
        <ul><li>Materials:
            <a href="https://github.com/hengruizhang98/CCA-SSG"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="assets/Seq2Bubble.pdf">
            Seq2Bubbles: Region-Based Embedding Learning for User Behaviors in Sequential Recommenders</a><br />
        <b>Qitian Wu</b>, Chenxiao Yang, Shuodian Yu, Xiaofeng Gao and Guihai Chen<br />
        <i>ACM International Conference on Information & Knowledge Management</i> <b>(CIKM 2021, spotlight)</b><br />
        <ul><li>Keywords: Sequential Recommendation, User Behavior Modeling, Geometrically-inspired Embedding</li></ul>
        <ul><li>Summary: Most of existing neural recommendation models embed a user behavior sequence into a single point in the latent space. To resolve the limited expressivity, we 
            propose to embed a sequence into a set of closed regions (hyper-ellipsoid) where center vectors can model a user's interests of multiple aspects and radius vectors
            could accommodate heterogeneous concentration over distinct aspects.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/Seq2Bubbles-slides.pdf"> Slides</a> |
            <a href="https://github.com/qitianwu/IDCF"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="https://arxiv.org/abs/2007.04833">
            Towards Open-World Recommendation: An Inductive Model-based Collaborative Filtering Approach</a><br />
        <b>Qitian Wu</b>, Hengrui Zhang, Xiaofeng Gao, Junchi Yan and Hongyuan Zha<br />
        <i>In International Conference on Machine Learning</i> <b>(ICML 2021)</b><br />
        <ul><li>Keywords: Inductive Representation Learning, Cold-start Recommendation/Learning, Matrix Completion, Graph Structure Learning.</li></ul>
        <ul><li>Summary: Recommender systems are often supposed to deal with new unseen users during testing time, though current methods mostly based on collaborative filtering or 
            matrix factorization are limited in transductive learning (training and testing data share the same user set). We piorneerly explore a new learning paradigm that leverages 
            representations of a group of held-out users to compute the representations for new ones in an inductive way. Interestingly, the new method guarantees the same representation
            capacity compared to classic matrix factorization. 
        </li></ul>
        <ul><li>Materials:
            <a href="assets/IDCF-slides.pdf"> Slides</a> |
            <a href="assets/IDCF-poster.png"> Poster</a> |
            <a href="https://github.com/qitianwu/IDCF"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="assets/LANTERN.pdf">
            Learning Latent Process from High-Dimensional Event Sequences via Efficient Sampling</a><br /> 
        <b>Qitian Wu</b>, Zixuan Zhang, Xiaofeng Gao, Junchi Yan and Guihai Chen<br /> 
        <i>In Advances in Neural Information Processing Systems</i> <b>(NeurIPS 2019)</b><br />
        <ul><li>Keywords: Temporal Point Process, Relation Inference, Sequence Transformer, Imitation Learning</li></ul>
        <ul><li>Summary: We target the modeling and generation of temporal dynamics in large interaction nodes with a latent graph topology. To this end,
            we propose an adversarial imitation learning framework composed of
            1) a latent structural intensity model that uncovers the latent graph and estimates the temporal dependency over sequence dynamics; 
            2) an efficient random walk based generation model that generates a sequence from a bottom-up view.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/LANTERN-poster.pdf"> Poster</a> |
            <a href="https://github.com/zhangzx-sjtu/LANTERN-NeurIPS-2019"> Codes</a>
        </li></ul>
    </li>
    <!-- <li>
        <a href="assets/Feature Evolution.pdf">
            Feature Evolution Based Multi-Task Learning for Collaborative Filtering with Social Trust</a><br /> 
        <b>Qitian Wu</b>, Lei Jiang, Xiaofeng Gao, Xiaochun Yang and Guihai Chen<br /> 
        <i>In International Joint Conference on Artificial Intelligence</i> <b>(IJCAI 2019)</b><br />
        <ul><li>Keywords: Collaborative Filtering, Network Embedding, Multi-Task Learning, Bayesian Optimization.</li></ul>
    </li> -->
    <li>
        <a href="assets/Dual Sequential.pdf">
            Dual Sequential Prediction Models Linking Sequential Recommendation and Information Dissemination</a><br /> 
        <b>Qitian Wu</b>, Yirui Gao, Xiaofeng Gao, Paul Weng and Guihai Chen<br />
        <i>In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i> <b>(KDD 2019)</b><br /> 
        <ul><li>Keywords: Sequential Recommendation, Information Diffusion, User Behavior Modeling.</li></ul>
        <ul><li>Summary: Sequential recommendation and information dissemination can be treated as symmetric problems where the sequence dynamics lie in user and item side, respectively.
            Based on this observation, we propose a dual learning model that resorts to mutual reinforcement between two sequential learning models via a teacher-student distillation loss.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/DEEMS-poster.png"> Poster</a> |
            <a href="https://github.com/qitianwu/DEEMS-KDD-19"> Codes</a>
        </li></ul>
        </li>
    <li>
        <a href="assets/Dual Graph.pdf">
            Dual Graph Attention Networks for Deep Latent Representation of Multifaceted Social Effects in Recommender Systems</a><br />       
        <b>Qitian Wu</b>, Hengrui Zhang, Xiaofeng Gao, Peng He, Paul Weng, Han Gao and Guihai Chen<br />
        <i>In World Wide Web Conference</i> <b>(WWW 2019, Oral)</b><br />
        <ul><li>Keywords: Social Recommendation, Graph Neural Networks, Multi-Armed Bandit, Policy Gradient</li></ul>
        <ul><li>Summary: There are multifaceted inter-dependence among user-item interactions in recommender systems. We design a dual graph attention architecture
            that simultaneously learns to capture user-user relations (given an observed social network) and item-item relations (given an item2item similarity graph) in a 
            fully data-driven manner. The graph attention networks are updated with recommendation models in an end-to-end fashion.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/DANSER-slides.png"> Slides</a> |
            <a href="assets/DANSER-poster.png"> Poster</a> |
            <a href="https://github.com/qitianwu/DANSER-WWW-19"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="https://dl.acm.org/doi/abs/10.1145/3269206.3271714">
            Adversarial Training Model Unifying Feature Driven and Point Process Perspectives for Event Popularity Prediction</a><br /> 
        <b>Qitian Wu</b>, Chaoqi Yang, Hengrui Zhang, Xiaofeng Gao, Paul Weng and Guihai Chen<br />
        <i>In ACM International Conference on Information and Knowledge Management</i> (CIKM 2018)</b><br />
        <ul><li>Keywords: Event Prediction, Point Process, Adversarial Training</li></ul>
        <ul><li>Summary: Predicting future events given histortical ones is a fundamental and pervasive problem in machine learning and data mining, with applications
            to social influence analysis, pandemic control and target advertisement. Feature driven methods and point process models are two schools of thinking in this area. 
            In this paper we propose an adversarial training model that combines both of the world through a two-player game.
        </li></ul>
    </li>
    <li>
        <a href="https://ieeexplore.ieee.org/document/8594984">
            EPAB: Early Pattern Aware Bayesian Model for Social Content Popularity Prediction</a><br /> 
        <b>Qitian Wu</b>, Chaoqi Yang, Xiaofeng Gao, Peng He and Guihai Chen<br />
        <i>In IEEE International Conference on Data Mining</i> (ICDM 2018)<br />
        <ul><li>Keywords: Information Diffusion, Bayesian Networks, Structure Searching</li></ul>
        <ul><li>Summary: This works focus on predicting the popularity of user generated content in social networks (e.g., tweets or weibo) and proposes a probabilistic framework based on
            Bayesian networks that is tailored for early-stage popularity prediction where the observed information is rare.
    </li>
</ul>


<h2>Selected Awards</h2>
<table style="border-spacing:2px">
    <tbody>
        <ul>
            <li>
                Baidu PhD Fellowship (only 10 from worldwide PhD students)
            </li>
            <li>
                Microsoft Research PhD Fellowship (only 11 in Asia)
            </li>
            <li>
                Baidu Global Top 100 Rising Stars in Artiﬁcial Intelligence
            </li>
            <li>
                National Scholarship (2016, 2017, top 1 in the department)
            </li>
            <li>
                The 1st-Class Academic Excellence Scholarship (2016, 2017, top 1 in the department)
            </li>
            <li>
                Lixin Tang Scholarship (2017, 2018)
            </li>
            <li> 
                Yuanqing Yang Scholarship (2019)
            </li>
            <li>
                Outstanding Winner, INFORMS Awards, Mathematical Contest in Modeling, Data Insights Problem
                (top 3 out of 4748 teams, the INFORMS Awards selects one team among all the participants) 
                <!--
                                    <a href="assets/72969.pdf">[paper]</a>
                <ul><li>Keywords: Gaussian Process Regression, Auto-Regressive Model, Multi-Objective Optimization.</li></ul>
                -->
            </li>
            <li>
                National Second Award, China Undergraduate Mathematical Contest in Modeling (top 5.8% in 28046 teams)
            </li>
            <li>
                First Award, Physics Competition of Chinese College Students (2015)
            </li>
            <li>
                Outstanding Graduate of Shanghai (2018)
            </li>
            <li>
                Excellent Thesis of Undergraduates in Department (2018)
            </li>
        </ul>
    </tbody>
</table>


<h2>Academic Service</h2>
<table style="border-spacing:2px">
    <tbody>
            <p>I will serve or served as the reviewer or (senior) PC member for TKDE, TNNLS, AAAI'21, CVPR'21, IJCAI'21, ICML'21, ICCV'21, NeurIPS'21, 
                ICLR'22, AAAI'22, CVPR'22, IJCAI'22, ICML'22, NeurIPS'22, AAAI'23, ICLR'23.</p>
    </tbody>
</table>


<!--
<h2>Activity</h2>
<table>
    <tbody>
        <tr>
            <th>
                <td>
                <img src="images/nips-poster1.jpg" border="0" width="130">
                </td>
                <td style="height: 5%"></td>
                <td>
                <img src="images/nips-poster2.jpg" border="0" width="130">
                </td>
            </th>
            <td style="width: 5%"></td>
            <td>
                <p><b>2019.12:</b> I attended NeurIPS'19 at Vancouver, Canada, and gave a poster presentation for our paper.</p>
            </td>
        </tr>
    </tbody>
</table>
<table>
    <tbody>
        <tr>
            <th>
                <td>
                <img src="images/www-pre.jpg" border="0" width="130">
                </td>
                <td style="height: 5%"></td>
                <td>
                <img src="images/www-poster.jpg" border="0" width="130">
                </td>
            </th>
            <td style="width: 5%"></td>
            <td>
                <p><b>2019.05:</b> I gave an oral presentation about our work in WWW'19 conference at San Francisco, USA.</p>
            </td>
        </tr>
    </tbody>
</table>
<table>
        <tbody>
            <tr>
                <th>
                    <td>
                        <img src="images/icdm-pre.jpg" border="0" width="130">
                        </td>
                        <td style="height: 5%"></td>
                        <td>
                        <img src="images/icdm-poster.jpg" border="0" width="130">
                    </td>
                </th>
                <td style="width: 5%"></td>
                <td>
                    <p><b>2018.11:</b> I attended ICDM'18 conference held at Singapore and gave an presentation about our work.</p>
                </td>
            </tr>
        </tbody>
    </table>

-->


<div id="footer">
    <div id="footer-text"></div>
</div>

</div>

</body></html>


<meta name="google-site-verification" content="Y50gVg4R1617ZJjuqs37mnvW9fMjlWxJ0J13I1sULSI" />
<meta name="description" content="Qitian Wu&#39;s home page">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Qitian Wu's Homepage @ Shanghai Jiao Tong University</title>

<script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?f38d019abe6aa72687acdcf683ca0515";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
</script>

<body>
<div id="layout-content" style="margin-top:25px">

<table>
    <tbody>
        <tr>
            <td width="670">
                <div id="toptitle">
                    <h1>Qitian Wu &nbsp; <!--<img src="images/name.png" height="45px" style="margin-bottom:-5px" alt=''>--></h1>
                </div>
                <p>
                    Shanghai Jiao Tong University <br>
                    Shanghai, China, 200240.<br>
                    Email: echo740@sjtu.edu.cn<br>
                    <!--
                    <a href="assets/cv.pdf">CV</a> |
                    -->
                    <a href="https://github.com/qitianwu">Github</a> | <a href="https://scholar.google.com/citations?user=m01-2qUAAAAJ&hl=zh-CN">Google Scholar</a>
                </p>
            </td>
        </tr>
    </tbody>
</table>
    

<table>
        <tbody>
            <tr>
                <th>
                    <img src="images/self3.jpeg" border="0" width="250">
                </th>
                <td style="width: 5%"></td>
                <td>
                    <p>I am now a PhD student at Department of Computer Science and Engineering from Shanghai Jiao Tong University (SJTU), supervised by Prof. Junchi Yan.
                        I achieved the Bachelor and Master degrees from SJTU.
                    </p>
                    <p>I am broadly interested in various research topics in machine learning and data mining, including 
                        representation learning, relation inference, robust learning, deep generative models, etc.,
                        as well as their applications such as recommender systems, advertisement and healthcare service.</p>
                    <p>In particular, my current research focus on representation and learning over complex structured data including graphs, sequences, sets, user
                        behaviors, etc. I would like to explore different perspectives to solve real problems, build models with enough expressiveness, scalability 
                        and generalizability, and endeavor on developing the
                        next generation of representation learning approaches for dynamic, open and uncertain environments.</p>

                </td>
            </tr>
        </tbody>
    </table>


<h2>Selected Publications <small></small></h2>
<ul>
    <li>
        <a href="https://proceedings.neurips.cc/paper/2021/file/a1c5aff9679455a233086e26b72b9a06-Paper.pdf">
            Towards Open-World Feature Extrapolation: An Inductive Graph Learning Approach</a>  <br />
        <b>Qitian Wu</b>, Chenxiao Yang and Junchi Yan<br />
        <i>Advances in Neural Information Processing Systems</i> <b>(NeurIPS 2021)</b><br />
        <ul><li>Keywords: Graph Neural Networks, Representation Learning, Extrapolation, Domain Shift</li></ul>
        <ul><li>Summary: We propose a new research problem (domain shift from training data to testing data with augmented input feature space) and design a graph
            learning approach that bridges seen and unseen features with instance nodes to achieve extrapolation to new feature space. 
            The `open-world' term emphasizes arbitrary new features from in-the-wild environments.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/FATE-slides.pdf"> Slides</a> |
            <a href="assets/FATE-poster.png"> Poster</a> |
            <a href="https://github.com/qitianwu/FATE"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="https://proceedings.neurips.cc/paper/2021/file/5db60c98209913790e4fcce4597ee37c-Paper.pdf">
            Bridging Explicit and Implicit Deep Generative Models via Neural Stein Estimators</a>  <br />
        <b>Qitian Wu</b>, Han Gao and Hongyuan Zha<br />
        <i>Advances in Neural Information Processing Systems</i> <b>(NeurIPS 2021)</b><br />
        <ul><li>Keywords: Deep Generative Models, Energy-based Model, Generative Adversarial Networks, Stein's Method</li></ul>
        <ul><li>Summary: Explicit generative models (e.g. energy-based model) and implicit generative models (e.g. GANs) have their respective pros and cons. We leverage
            the Stein discrepancy to construct a novel bridging term to connect two models in a unified framework. We theoretically show that such an approach induces effective
            dual regularization effects and could empirically facilitate the learning of the both.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/Stein-slides.pdf"> Slides</a> |
            <a href="assets/Stein-poster.png"> Poster</a> |
            <a href="https://github.com/qitianwu/SteinBridging"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="https://proceedings.neurips.cc/paper/2021/file/00ac8ed3b4327bdd4ebbebcb2ba10a00-Paper.pdf">
            From Canonical Correlation Analysis to Self-supervised Graph Neural Networks</a><br />
        Hengrui Zhang, <b>Qitian Wu</b>, Junchi Yan, David Wipf and Philip S. Yu<br />
        <i>Advances in Neural Information Processing Systems</i> <b>(NeurIPS 2021)</b><br />
        <ul><li>Keywords: Graph Neural Networks, Self-supervised Representation Learning, Contrastive Learning</li></ul>
        <ul><li>Summary: We introduce a simple yet effective contrastive objective for self-supervised node representation learning over graphs. 
            Compared with other works, our approach requires none of the parameterized mutual information estimator, additional projector, asymmetric structures, and most importantly, negative samples which can be costly.
        </li></ul>
        <ul><li>Materials:
            <a href="https://github.com/hengruizhang98/CCA-SSG"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="assets/Seq2Bubble.pdf">
            Seq2Bubbles: Region-Based Embedding Learning for User Behaviors in Sequential Recommenders</a><br />
        <b>Qitian Wu</b>, Chenxiao Yang, Shuodian Yu, Xiaofeng Gao and Guihai Chen<br />
        <i>ACM International Conference on Information & Knowledge Management</i> <b>(CIKM 2021, spotlight)</b><br />
        <ul><li>Keywords: Sequential Recommendation, User Behavior Modeling, Geometrically-inspired Embedding</li></ul>
        <ul><li>Summary: Most of existing neural recommendation models embed a user behavior sequence into a single point in the latent space. To resolve the limited expressivity, we 
            propose to embed a sequence into a set of closed regions (hyper-ellipsoid) where center vectors can model a user's interests of multiple aspects and radius vectors
            could accommodate heterogeneous concentration over distinct aspects.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/Seq2Bubbles-slides.pdf"> Slides</a> |
            <a href="https://github.com/qitianwu/IDCF"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="https://arxiv.org/abs/2007.04833">
            Towards Open-World Recommendation: An Inductive Model-based Collaborative Filtering Approach</a><br />
        <b>Qitian Wu</b>, Hengrui Zhang, Xiaofeng Gao, Junchi Yan and Hongyuan Zha<br />
        <i>In International Conference on Machine Learning</i> <b>(ICML 2021)</b><br />
        <ul><li>Keywords: Inductive Representation Learning, Cold-start Recommendation/Learning, Matrix Completion, Graph Structure Learning.</li></ul>
        <ul><li>Summary: Recommender systems are often supposed to deal with new unseen users during testing time, though current methods mostly based on collaborative filtering or 
            matrix factorization are limited in transductive learning (training and testing data share the same user set). We piorneerly explore a new learning paradigm that leverages 
            representations of a group of held-out users to compute the representations for new ones in an inductive way. Interestingly, the new method guarantees the same representation
            capacity compared to classic matrix factorization. 
        </li></ul>
        <ul><li>Materials:
            <a href="assets/IDCF-slides.pdf"> Slides</a> |
            <a href="assets/IDCF-poster.png"> Poster</a> |
            <a href="https://github.com/qitianwu/IDCF"> Codes</a>
        </li></ul>
    </li>
    <li>
        <a href="assets/LANTERN.pdf">
            Learning Latent Process from High-Dimensional Event Sequences via Efficient Sampling</a><br /> 
        <b>Qitian Wu</b>, Zixuan Zhang, Xiaofeng Gao, Junchi Yan and Guihai Chen<br /> 
        <i>In Advances in Neural Information Processing Systems</i> <b>(NeurIPS 2019)</b><br />
        <ul><li>Keywords: Temporal Point Process, Relation Inference, Sequence Transformer, Imitation Learning</li></ul>
        <ul><li>Summary: We target the modeling and generation of temporal dynamics in large interaction nodes with a latent graph topology. To this end,
            we propose an adversarial imitation learning framework composed of
            1) a latent structural intensity model that uncovers the latent graph and estimates the temporal dependency over sequence dynamics; 
            2) an efficient random walk based generation model that generates a sequence from a bottom-up view.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/LANTERN-poster.pdf"> Poster</a> |
            <a href="https://github.com/zhangzx-sjtu/LANTERN-NeurIPS-2019"> Codes</a>
        </li></ul>
    </li>
    <!-- <li>
        <a href="assets/Feature Evolution.pdf">
            Feature Evolution Based Multi-Task Learning for Collaborative Filtering with Social Trust</a><br /> 
        <b>Qitian Wu</b>, Lei Jiang, Xiaofeng Gao, Xiaochun Yang and Guihai Chen<br /> 
        <i>In International Joint Conference on Artificial Intelligence</i> <b>(IJCAI 2019)</b><br />
        <ul><li>Keywords: Collaborative Filtering, Network Embedding, Multi-Task Learning, Bayesian Optimization.</li></ul>
    </li> -->
    <li>
        <a href="assets/Dual Sequential.pdf">
            Dual Sequential Prediction Models Linking Sequential Recommendation and Information Dissemination</a><br /> 
        <b>Qitian Wu</b>, Yirui Gao, Xiaofeng Gao, Paul Weng and Guihai Chen<br />
        <i>In ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i> <b>(KDD 2019)</b><br /> 
        <ul><li>Keywords: Sequential Recommendation, Information Diffusion, User Behavior Modeling.</li></ul>
        <ul><li>Summary: Sequential recommendation and information dissemination can be treated as symmetric problems where the sequence dynamics lie in user and item side, respectively.
            Based on this observation, we propose a dual learning model that resorts to mutual reinforcement between two sequential learning models via a teacher-student distillation loss.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/DEEMS-poster.png"> Poster</a> |
            <a href="https://github.com/qitianwu/DEEMS-KDD-19"> Codes</a>
        </li></ul>
        </li>
    <li>
        <a href="assets/Dual Graph.pdf">
            Dual Graph Attention Networks for Deep Latent Representation of Multifaceted Social Effects in Recommender Systems</a><br />       
        <b>Qitian Wu</b>, Hengrui Zhang, Xiaofeng Gao, Peng He, Paul Weng, Han Gao and Guihai Chen<br />
        <i>In World Wide Web Conference</i> <b>(WWW 2019, Oral)</b><br />
        <ul><li>Keywords: Social Recommendation, Graph Neural Networks, Multi-Armed Bandit, Policy Gradient</li></ul>
        <ul><li>Summary: There are multifaceted inter-dependence among user-item interactions in recommender systems. We design a dual graph attention architecture
            that simultaneously learns to capture user-user relations (given an observed social network) and item-item relations (given an item2item similarity graph) in a 
            fully data-driven manner. The graph attention networks are updated with recommendation models in an end-to-end fashion.
        </li></ul>
        <ul><li>Materials:
            <a href="assets/DANSER-slides.png"> Slides</a> |
            <a href="assets/DANSER-poster.png"> Poster</a> |
            <a href="https://github.com/qitianwu/DANSER-WWW-19"> Codes</a>
        </li></ul>
    </li>
    <!-- <li>
        <a href="assets/Early Pattern.pdf">
            EPAB: Early Pattern Aware Bayesian Model for Social Content Popularity Prediction</a><br /> 
        <b>Qitian Wu</b>, Chaoqi Yang, Xiaofeng Gao, Peng He and Guihai Chen<br />
        <i>In IEEE International Conference on Data Mining</i> (ICDM 2018)<br />
        <ul><li>Keywords: Information Diffusion, Bayesian Networks, Structure Searching</li></ul>
    </li> -->
    <!-- <li>
        <a href="assets/Adversarial Training.pdf">
            Adversarial Training Model Unifying Feature Driven and Point Process Perspectives for Event Popularity Prediction</a><br /> 
        <b>Qitian Wu</b>, Chaoqi Yang, Hengrui Zhang, Xiaofeng Gao, Paul Weng and Guihai Chen<br />
        <i>In ACM International Conference on Information and Knowledge Management</i> (CIKM 2018)</b><br />
        <ul><li>Keywords: Event Prediction, Point Process, Adversarial Training</li></ul>
    </li> -->
</ul>


<h2>Selected Awards</h2>
<table style="border-spacing:2px">
    <tbody>
        <ul>
            <li>
                2021 Baidu Scholarship (only 10 from worldwide)
            </li>
            <li>
                2021 Microsoft Research Asia PhD Fellowship (only 11 in Asia)
            </li>
            <li>
                Baidu Global Top 100 Chinese Rising Stars in Artiﬁcial Intelligence (2021)
            </li>
            <li>
                National Scholarship (2016, 2017)
            </li>
            <li>
                The 1st-Class Academic Excellence Scholarship (2016, 2017)
            </li>
            <li>
                Lixin Tang Scholarship (2017, 2018)
            </li>
            <li> 
                Yuanqing Yang Scholarship (2019)
            </li>
            <li>
                Outstanding Winner, INFORMS Awards, Mathematical Contest in Modeling, Data Insights Problem
                (top 3 out of 4748 teams, the INFORMS Awards selects one team among all the participants) 
                <!--
                                    <a href="assets/72969.pdf">[paper]</a>
                <ul><li>Keywords: Gaussian Process Regression, Auto-Regressive Model, Multi-Objective Optimization.</li></ul>
                -->
            </li>
            <li>
                National Second Award, China Undergraduate Mathematical Contest in Modeling (top 5.8% in 28046 teams)
            </li>
            <li>
                First Award, Physics Competition of Chinese College Students (2015)
            </li>
            <li>
                Outstanding Graduate of Shanghai (2018)
            </li>
            <li>
                Excellent Thesis of Undergraduates in Department (2018)
            </li>
        </ul>
    </tbody>
</table>


<h2>Academic Service</h2>
<table style="border-spacing:2px">
    <tbody>
        <ul>
            <p>I served as the reviewer or PC member for TKDE, TNNLS, AAAI'21, CVPR'21, IJCAI'21, ICML'21, ICCV'21, NeurIPS'21, 
                ICLR'22, AAAI'22, CVPR'22, IJCAI'22, ICML'22.</p>
        </ul>
    </tbody>
</table>


<!--
<h2>Activity</h2>
<table>
    <tbody>
        <tr>
            <th>
                <td>
                <img src="images/nips-poster1.jpg" border="0" width="130">
                </td>
                <td style="height: 5%"></td>
                <td>
                <img src="images/nips-poster2.jpg" border="0" width="130">
                </td>
            </th>
            <td style="width: 5%"></td>
            <td>
                <p><b>2019.12:</b> I attended NeurIPS'19 at Vancouver, Canada, and gave a poster presentation for our paper.</p>
            </td>
        </tr>
    </tbody>
</table>
<table>
    <tbody>
        <tr>
            <th>
                <td>
                <img src="images/www-pre.jpg" border="0" width="130">
                </td>
                <td style="height: 5%"></td>
                <td>
                <img src="images/www-poster.jpg" border="0" width="130">
                </td>
            </th>
            <td style="width: 5%"></td>
            <td>
                <p><b>2019.05:</b> I gave an oral presentation about our work in WWW'19 conference at San Francisco, USA.</p>
            </td>
        </tr>
    </tbody>
</table>
<table>
        <tbody>
            <tr>
                <th>
                    <td>
                        <img src="images/icdm-pre.jpg" border="0" width="130">
                        </td>
                        <td style="height: 5%"></td>
                        <td>
                        <img src="images/icdm-poster.jpg" border="0" width="130">
                    </td>
                </th>
                <td style="width: 5%"></td>
                <td>
                    <p><b>2018.11:</b> I attended ICDM'18 conference held at Singapore and gave an presentation about our work.</p>
                </td>
            </tr>
        </tbody>
    </table>

-->


<div id="footer">
    <div id="footer-text"></div>
</div>

</div>

</body></html>

